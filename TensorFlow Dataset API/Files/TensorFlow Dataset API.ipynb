{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset pipeline from numpy or lists\n",
    "\n",
    "Tensorflow dataset is used work with large datasets and to \"create complex pipelines from simple, reusable pieces\". instead of loading your entire data on the start, it loads each batch when needed.\n",
    "This comes in handy when working with large amounts of data, which in machine learning is most of the time. think about it like using a file stream, you dont read the entire file but instead you read it line by line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(15, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# From lists or numpy arrays\n",
    "data = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "dataset = Dataset.from_tensor_slices(data)\n",
    "\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying instructions (transformations)\n",
    "\n",
    "Because your data is loaded only when accessed, you can specify a set of instructions that your data will go through right after you load it.\n",
    "\n",
    "Your instructions would execute only when your dataset is being accessed, an example of it is when you iterate on your dataset yourself or when fitting a model.\n",
    "\n",
    "When you access your dataset it should execute all instructions (I.e. map, etc) per batch. It doesn’t do it for all the dataset before you need it, that’s the point of the dataset API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32) tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32) tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32) tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32) tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32) tf.Tensor(20, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32) tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32) tf.Tensor(24, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32) tf.Tensor(26, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32) tf.Tensor(28, shape=(), dtype=int32)\n",
      "tf.Tensor(15, shape=(), dtype=int32) tf.Tensor(30, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Map\n",
    "dataset = dataset.map(lambda x: (x, x*2))\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 1, 2])>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([10,  2,  4])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 4,  6, 10])>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 8, 12, 20])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 9, 12,  3])>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([18, 24,  6])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([13,  7, 11])>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([26, 14, 22])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([14,  8, 15])>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([28, 16, 30])>)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "dataset = dataset.shuffle(5)\n",
    "\n",
    "# Batch\n",
    "dataset = dataset.batch(3)\n",
    "\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5403023, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.41614684, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.9899925, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.6536436, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2836622, shape=(), dtype=float32)\n",
      "tf.Tensor(0.96017027, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75390226, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.14550003, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.91113025, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.8390715, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004425698, shape=(), dtype=float32)\n",
      "tf.Tensor(0.84385395, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9074468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13673721, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.7596879, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# From generator function\n",
    "def dataset_generator():\n",
    "    for x in data:\n",
    "        yield np.cos(x)\n",
    "\n",
    "dataset = dataset.from_generator(dataset_generator, tf.float32)\n",
    "for x in dataset:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Tensors\n",
    "\n",
    "When doing transformations on a dataset pipeline, you are working with Tensors and not Numpy arrays and we need to adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 6, 2])>, <tf.Tensor: shape=(3, 31), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0]])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 8])>, <tf.Tensor: shape=(3, 31), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0]])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 11,  4])>, <tf.Tensor: shape=(3, 31), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0]])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([10, 14, 12])>, <tf.Tensor: shape=(3, 31), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0]])>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 9, 15, 13])>, <tf.Tensor: shape=(3, 31), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0]])>)\n"
     ]
    }
   ],
   "source": [
    "def func(x, y):\n",
    "    return x, keras.utils.to_categorical(y, 31)\n",
    "\n",
    "# one_hot instead of to_categorical\n",
    "# dataset = dataset.map(func)\n",
    "\n",
    "# Wrapping functions with py_function\n",
    "dataset = dataset.map(lambda x, y: tf.py_function(func, [x, y], [tf.int32, tf.int32]))\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training your model with the Dataset API\n",
    "You can train your model with your dataset with ease! just pass it to the .fit() and your good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.skip(2)\n",
    "valid = dataset.take(2)\n",
    "\n",
    "model = keras.Model()\n",
    "model.fit(train, epochs=5, validation_data=valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
